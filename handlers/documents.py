import logging
from telegram import Update, ReplyKeyboardMarkup, ReplyKeyboardRemove, InputFile
from telegram.ext import ContextTypes, ConversationHandler

from keyboards import DONE_UPLOADING
from states import UPLOAD_DOCUMENTS, MANUAL_INPUT
from utils.fields import get_field_description
from utils.gpt import extract_doc_fields_with_gpt
from utils.ocr import convert_pdf_to_png, gcv_ocr, gcv_ocr_multiple
from utils.parsers import (
    parse_passport_fields, parse_migration_fields, parse_patent_fields,
    parse_dms_fields, parse_contract_fields
)
from utils.prompts import (
    PROMPT_PASSPORT, PROMPT_MIGRATION, PROMPT_PATENT,
    PROMPT_DMS, PROMPT_CONTRACT
)
from utils.word import create_passport_translation_doc

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logger = logging.getLogger(__name__)

async def upload_documents(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    - –î–ª—è —É—Å–ª—É–≥–∏ "–ü–µ—Ä–µ–≤–æ–¥ –ø–∞—Å–ø–æ—Ä—Ç–∞" —Å—Ä–∞–∑—É –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–µ—Ä–µ–≤–æ–¥ –∏ –∑–∞–≤–µ—Ä—à–∞–µ—Ç –¥–∏–∞–ª–æ–≥.
    - –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —É—Å–ª—É–≥ —Å–æ–±–∏—Ä–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–æ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–∫–∏ "–ó–∞–≤–µ—Ä—à–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É".
    """
    message = update.message
    user_data = context.user_data
    service_type = user_data.get('service')

    # --- –°—Ü–µ–Ω–∞—Ä–∏–π 1: –ü–µ—Ä–µ–≤–æ–¥ –ø–∞—Å–ø–æ—Ä—Ç–∞ ---
    if service_type == '–ü–µ—Ä–µ–≤–æ–¥ –ø–∞—Å–ø–æ—Ä—Ç–∞':
        if not (message.document or message.photo):
            await message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ —Ñ–æ—Ç–æ –∏–ª–∏ PDF –ø–∞—Å–ø–æ—Ä—Ç–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞.")
            return UPLOAD_DOCUMENTS

        file_obj = await (message.document or message.photo[-1]).get_file()
        file_name = message.document.file_name if message.document else "photo.jpg"
        
        await message.reply_text(f"üì• –ó–∞–≥—Ä—É–∂–∞—é –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {file_name}...")
        try:
            file_bytes = await file_obj.download_as_bytearray()
            raw_text = gcv_ocr(bytes(file_bytes))
            if not raw_text:
                await message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª.")
                return UPLOAD_DOCUMENTS

            gpt_response = await extract_doc_fields_with_gpt(raw_text, PROMPT_PASSPORT)
            if "–û—à–∏–±–∫–∞" in gpt_response:
                await message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ GPT: {gpt_response}")
                return UPLOAD_DOCUMENTS

            fields = parse_passport_fields(gpt_response)
            word_bytes = create_passport_translation_doc(fields)
            
            await message.reply_document(
                document=InputFile(word_bytes, filename="–ü–µ—Ä–µ–≤–æ–¥_–ø–∞—Å–ø–æ—Ä—Ç–∞.docx"),
                caption="‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –ø–∞—Å–ø–æ—Ä—Ç–∞ –≥–æ—Ç–æ–≤!"
            )
            await message.reply_text("üèÅ –†–∞–±–æ—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –î–ª—è –Ω–æ–≤–æ–≥–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –≤–≤–µ–¥–∏—Ç–µ /start", reply_markup=ReplyKeyboardRemove())
            return ConversationHandler.END
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ –ø–∞—Å–ø–æ—Ä—Ç–∞: {e}", exc_info=True)
            await message.reply_text(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
            return ConversationHandler.END

    # --- –°—Ü–µ–Ω–∞—Ä–∏–π 2: –û—Å—Ç–∞–ª—å–Ω—ã–µ —É—Å–ª—É–≥–∏ ---
    # –ù–∞–∂–∞—Ç–∏–µ –∫–Ω–æ–ø–∫–∏ "–ó–∞–≤–µ—Ä—à–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É"
    if message.text and "–∑–∞–≤–µ—Ä—à–∏—Ç—å" in message.text.lower():
        required_docs = 4 if service_type == "–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç —Ä–∞–±–æ—Ç–Ω–∏–∫–∞ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω–æ–≥–æ –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞" else 3
        current_docs = len(user_data.get('documents', []))
        if current_docs < required_docs:
            await message.reply_text(
                f"‚ùå –ó–∞–≥—Ä—É–∂–µ–Ω–æ {current_docs} –∏–∑ {required_docs} –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ.",
                reply_markup=ReplyKeyboardMarkup(DONE_UPLOADING, resize_keyboard=True)
            )
            return UPLOAD_DOCUMENTS
        await message.reply_text("‚è≥ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...", reply_markup=ReplyKeyboardRemove())
        return await process_documents(update, context)

    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
    if message.document or message.photo:
        file_obj = await (message.document or message.photo[-1]).get_file()
        file_name = message.document.file_name if message.document else "photo.jpg"
        mime_type = message.document.mime_type if message.document else "image/jpeg"
        
        await message.reply_text(f"üì• –ó–∞–≥—Ä—É–∂–∞—é: {file_name}...")
        try:
            file_bytes = await file_obj.download_as_bytearray()
            user_data.setdefault('documents', []).append({
                'bytes': bytes(file_bytes), 'name': file_name, 'mime': mime_type
            })
            count = len(user_data['documents'])
            await message.reply_text(
                f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω! –í—Å–µ–≥–æ: {count}\n"
                "–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ 'üèÅ –ó–∞–≤–µ—Ä—à–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É'.",
                reply_markup=ReplyKeyboardMarkup(DONE_UPLOADING, resize_keyboard=True)
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}", exc_info=True)
            await message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {e}")
    else:
        await message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ '–ó–∞–≤–µ—Ä—à–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É'.")

    return UPLOAD_DOCUMENTS


async def process_documents(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã, –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ.
    """
    user_data = context.user_data
    documents = user_data.get('documents', [])
    service_type = user_data.get('service', '')

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤–∞—Ä–µ–π –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
    user_data.update({
        'passport_fields': {}, 'migration_fields': {}, 'patent_fields': {},
        'dms_fields': {}, 'contract_fields': {}, 'manual_fields': {}, 'missing_fields': []
    })

    # –ö–∞—Ä—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {–∫–ª—é—á–µ–≤–æ–µ_—Å–ª–æ–≤–æ: (—Ç–∏–ø_–¥–æ–∫—É–º–µ–Ω—Ç–∞, –ø—Ä–æ–º–ø—Ç, –ø–∞—Ä—Å–µ—Ä, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ_–ø–æ–ª—è)}
    processing_map = {
        '–ø–∞—Å–ø–æ—Ä—Ç': ('passport', PROMPT_PASSPORT, parse_passport_fields, ['fio', 'birthdate', 'passport_number']),
        '–ø–∞—Ç–µ–Ω—Ç': ('patent', PROMPT_PATENT, parse_patent_fields, ['patent_number', 'patent_date', 'patent_blank']),
    }

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ –ø–æ–ª–µ–π –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Å–ª—É–≥–∏
    if service_type == "–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç —Ä–∞–±–æ—Ç–Ω–∏–∫–∞ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω–æ–≥–æ –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞":
        processing_map['–ø–∞—Ç–µ–Ω—Ç'][3].append('inn') # –î–æ–±–∞–≤–ª—è–µ–º –ò–ù–ù –≤ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –¥–ª—è –ø–∞—Ç–µ–Ω—Ç–∞
        processing_map['–¥–º—Å'] = ('dms', PROMPT_DMS, parse_dms_fields, ['policy_number', 'dms_insurer_phone', 'dms_insurer_email'])
        processing_map['–¥–æ–≥–æ–≤–æ—Ä'] = ('contract', PROMPT_CONTRACT, parse_contract_fields, ['position', 'contract_date'])
    else: # –î–ª—è –¥—Ä—É–≥–∏—Ö —É—Å–ª—É–≥
        processing_map['–º–∏–≥—Ä–∞—Ü–∏–æ–Ω'] = ('migration', PROMPT_MIGRATION, parse_migration_fields, ['migration_card_number', 'migration_card_date'])


    processed_docs_indices = set()

    for keyword, (doc_type, prompt, parser, req_fields) in processing_map.items():
        processed_this_type = False
        for i, doc in enumerate(documents):
            if i in processed_docs_indices:
                continue
            
            # –ò—â–µ–º –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            search_keywords = [keyword]
            if keyword == '–¥–æ–≥–æ–≤–æ—Ä':
                search_keywords.append('—Ç–¥')
            if keyword == '–¥–º—Å':
                search_keywords.append('—Å—Ç—Ä–∞—Ö–æ–≤')

            if any(kw in doc['name'].lower() for kw in search_keywords):
                await update.message.reply_text(f"üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {doc['name']}...")
                try:
                    if doc['mime'] == 'application/pdf':
                        png_pages = convert_pdf_to_png(doc['bytes'])
                        raw_text = gcv_ocr_multiple(png_pages) if png_pages else ""
                    else:
                        raw_text = gcv_ocr(doc['bytes'])

                    if raw_text:
                        fields_raw = await extract_doc_fields_with_gpt(raw_text, prompt)
                        data = parser(fields_raw)
                        user_data[f'{doc_type}_fields'] = data
                        
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
                        for field in req_fields:
                            if not data.get(field) or data.get(field) == '–ù–µ –Ω–∞–π–¥–µ–Ω–æ':
                                user_data['missing_fields'].append((doc_type, field))
                        
                        processed_this_type = True
                        processed_docs_indices.add(i)
                        await update.message.reply_text(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {doc['name']}")
                        break # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Ç–∏–ø—É –¥–æ–∫—É–º–µ–Ω—Ç–∞
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ '{doc['name']}': {e}", exc_info=True)
                    await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {doc['name']}. –ü–æ–ø—Ä–æ–±—É—é –∑–∞–ø—Ä–æ—Å–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤—Ä—É—á–Ω—É—é.")
        
        if not processed_this_type:
            await update.message.reply_text(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç —Ç–∏–ø–∞ '{keyword.capitalize()}'. –ó–∞–ø—Ä–æ—à—É –¥–∞–Ω–Ω—ã–µ –≤—Ä—É—á–Ω—É—é.")
            # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è —ç—Ç–æ–≥–æ —Ç–∏–ø–∞ –∫–∞–∫ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ
            for field in req_fields:
                user_data['missing_fields'].append((doc_type, field))

    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –ø–æ–ª–µ–π, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
    unique_missing_fields = []
    seen = set()
    for item in user_data['missing_fields']:
        if item not in seen:
            unique_missing_fields.append(item)
            seen.add(item)
    user_data['missing_fields'] = unique_missing_fields

    # –ó–∞–ø—Ä–æ—Å –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –ø–æ–ª–µ–π
    if user_data['missing_fields']:
        next_field_type, next_field_name = user_data['missing_fields'][0]
        field_desc = get_field_description(next_field_type, next_field_name)
        await update.message.reply_text(f"üìù –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ: {field_desc}")
        return MANUAL_INPUT

    # –ï—Å–ª–∏ –≤—Å–µ –Ω–∞ –º–µ—Å—Ç–µ, —Å–æ—Ö—Ä–∞–Ω—è–µ–º
    from handlers.manual import save_application
    return await save_application(update, context)
